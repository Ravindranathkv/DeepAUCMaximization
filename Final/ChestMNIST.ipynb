{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrOSGZI-vH3d"
      },
      "source": [
        "LibAUC Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libAUC and medMNIST\n",
        "!pip install libauc==1.2.0\n",
        "!pip install medmnist\n",
        "!pip install tensorboardX\n",
        "!pip install acsconv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk2NLXFSyD74",
        "outputId": "819cd0b7-5d5f-4eac-8988-f16fee9c8d52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libauc==1.2.0\n",
            "  Downloading libauc-1.2.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (4.7.0.72)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.5.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (16.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2022.7.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.10.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2023.4.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (23.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->libauc==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2->libauc==1.2.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2->libauc==1.2.0) (1.3.0)\n",
            "Installing collected packages: libauc\n",
            "Successfully installed libauc-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.1+cu118)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.4.12)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=9d70d305aa820b218f609047314807d5915a18130b990a87fffbedbdbf254423\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting acsconv\n",
            "  Downloading ACSConv-0.1.1.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from acsconv) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from acsconv) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from acsconv) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from acsconv) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from acsconv) (4.65.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from acsconv) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from acsconv) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from acsconv) (1.10.1)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (from acsconv) (2.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from acsconv) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from acsconv) (0.15.1+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->acsconv) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->acsconv) (2.3.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->acsconv) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->acsconv) (2022.7.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->acsconv) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->acsconv) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->acsconv) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->acsconv) (3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->acsconv) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->acsconv) (1.2.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardx->acsconv) (3.20.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->acsconv) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->acsconv) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->acsconv) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->acsconv) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->acsconv) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->acsconv) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->acsconv) (16.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->acsconv) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->acsconv) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->acsconv) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->acsconv) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->acsconv) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->acsconv) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->acsconv) (1.3.0)\n",
            "Building wheels for collected packages: acsconv\n",
            "  Building wheel for acsconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acsconv: filename=ACSConv-0.1.1-py3-none-any.whl size=24201 sha256=cd79163819706fecc66bde6732281dc59a41a7e041674940cc847becdc8f53e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/b1/ef/43fe6db442ef60fc6a8c7f98f330672eeca58463ebef542e62\n",
            "Successfully built acsconv\n",
            "Installing collected packages: acsconv\n",
            "Successfully installed acsconv-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gKlAkVBkvH3e"
      },
      "outputs": [],
      "source": [
        "from libauc.models import resnet18\n",
        "from libauc.losses import AUCMLoss\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "\n",
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.models import densenet121 as DenseNet121\n",
        "from libauc.datasets import CheXpert\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VV-WvgGGvH3f"
      },
      "outputs": [],
      "source": [
        "# data_flag = 'pathmnist'\n",
        "data_flag = 'chestmnist'\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 8\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XQIPfC8pvH3f",
        "outputId": "955c4390-e1c2-4b9c-b38e-4bc471a354a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'multi-label, binary-class'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V-gDHluvH3g",
        "outputId": "fc00a1fc-85c8-458a-b9d0-6bb3fd04c6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/chestmnist.npz?download=1 to /root/.medmnist/chestmnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 82802576/82802576 [00:06<00:00, 12137964.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/chestmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/chestmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/chestmnist.npz\n"
          ]
        }
      ],
      "source": [
        "data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Grayscale(3),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(degrees=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(0.5, 0.5),\n",
        "        ])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "val_dataset = DataClass(split='val', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = torch_data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = torch_data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = torch_data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff3jGbWSvH3g",
        "outputId": "de002615-a397-466e-ff83-0d45b11fcbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration started\n",
            "Epoch : 000  Train Loss : 0.12257 Val Loss : 0.02780   BatchID= 0   Val_AUC=0.4964   Best_Val_AUC=0.4964\n",
            "Epoch : 0\n",
            "Iteration started\n",
            "Epoch : 001  Train Loss : 0.12370 Val Loss : 0.03827   BatchID= 0   Val_AUC=0.5037   Best_Val_AUC=0.5037\n",
            "Epoch : 1\n",
            "Iteration started\n",
            "Epoch : 002  Train Loss : 0.11881 Val Loss : 0.03175   BatchID= 0   Val_AUC=0.5068   Best_Val_AUC=0.5068\n",
            "Epoch : 2\n",
            "Iteration started\n",
            "Epoch : 003  Train Loss : 0.15592 Val Loss : 0.00663   BatchID= 0   Val_AUC=0.5043   Best_Val_AUC=0.5068\n",
            "Epoch : 3\n",
            "Iteration started\n",
            "Epoch : 004  Train Loss : 0.09952 Val Loss : -0.02838   BatchID= 0   Val_AUC=0.5044   Best_Val_AUC=0.5068\n",
            "Epoch : 4\n",
            "Iteration started\n",
            "Epoch : 005  Train Loss : 0.15463 Val Loss : -0.06696   BatchID= 0   Val_AUC=0.5085   Best_Val_AUC=0.5085\n",
            "Epoch : 5\n",
            "Iteration started\n",
            "Epoch : 006  Train Loss : 0.16012 Val Loss : -0.10333   BatchID= 0   Val_AUC=0.4982   Best_Val_AUC=0.5085\n",
            "Epoch : 6\n",
            "Iteration started\n",
            "Epoch : 007  Train Loss : 0.14152 Val Loss : -0.13291   BatchID= 0   Val_AUC=0.4998   Best_Val_AUC=0.5085\n",
            "Epoch : 7\n",
            "Iteration started\n",
            "Epoch : 008  Train Loss : 0.15744 Val Loss : -0.16113   BatchID= 0   Val_AUC=0.4979   Best_Val_AUC=0.5085\n",
            "Epoch : 8\n",
            "Iteration started\n",
            "Epoch : 009  Train Loss : -0.08126 Val Loss : -0.18677   BatchID= 0   Val_AUC=0.5075   Best_Val_AUC=0.5085\n",
            "Epoch : 9\n",
            "Iteration started\n",
            "Epoch : 010  Train Loss : -0.09647 Val Loss : -0.19870   BatchID= 0   Val_AUC=0.5028   Best_Val_AUC=0.5085\n",
            "Epoch : 10\n",
            "Iteration started\n",
            "Epoch : 011  Train Loss : 0.10293 Val Loss : -0.20189   BatchID= 0   Val_AUC=0.4975   Best_Val_AUC=0.5085\n",
            "Epoch : 11\n",
            "Iteration started\n",
            "Epoch : 012  Train Loss : -0.20342 Val Loss : -0.19337   BatchID= 0   Val_AUC=0.5101   Best_Val_AUC=0.5101\n",
            "Epoch : 12\n",
            "Iteration started\n",
            "Epoch : 013  Train Loss : 0.11632 Val Loss : -0.17636   BatchID= 0   Val_AUC=0.5092   Best_Val_AUC=0.5101\n",
            "Epoch : 13\n",
            "Iteration started\n",
            "Epoch : 014  Train Loss : 0.13766 Val Loss : -0.15301   BatchID= 0   Val_AUC=0.5044   Best_Val_AUC=0.5101\n",
            "Epoch : 14\n",
            "Iteration started\n",
            "Epoch : 015  Train Loss : 0.11251 Val Loss : -0.12260   BatchID= 0   Val_AUC=0.5082   Best_Val_AUC=0.5101\n",
            "Epoch : 15\n",
            "Iteration started\n",
            "Epoch : 016  Train Loss : 0.11324 Val Loss : -0.08714   BatchID= 0   Val_AUC=0.5058   Best_Val_AUC=0.5101\n",
            "Epoch : 16\n",
            "Iteration started\n",
            "Epoch : 017  Train Loss : 0.12561 Val Loss : -0.05870   BatchID= 0   Val_AUC=0.5072   Best_Val_AUC=0.5101\n",
            "Epoch : 17\n",
            "Iteration started\n",
            "Epoch : 018  Train Loss : 0.07421 Val Loss : -0.00154   BatchID= 0   Val_AUC=0.5117   Best_Val_AUC=0.5117\n",
            "Epoch : 18\n",
            "Iteration started\n",
            "Epoch : 019  Train Loss : -0.04850 Val Loss : 0.07161   BatchID= 0   Val_AUC=0.5061   Best_Val_AUC=0.5117\n",
            "Epoch : 19\n",
            "Iteration started\n",
            "Epoch : 020  Train Loss : 0.12383 Val Loss : 0.11576   BatchID= 0   Val_AUC=0.5024   Best_Val_AUC=0.5117\n",
            "Epoch : 20\n",
            "Iteration started\n",
            "Epoch : 021  Train Loss : 0.13284 Val Loss : 0.16648   BatchID= 0   Val_AUC=0.5035   Best_Val_AUC=0.5117\n",
            "Epoch : 21\n",
            "Iteration started\n",
            "Epoch : 022  Train Loss : -0.22808 Val Loss : 0.24414   BatchID= 0   Val_AUC=0.4969   Best_Val_AUC=0.5117\n",
            "Epoch : 22\n",
            "Iteration started\n",
            "Epoch : 023  Train Loss : 0.10558 Val Loss : 0.31801   BatchID= 0   Val_AUC=0.5011   Best_Val_AUC=0.5117\n",
            "Epoch : 23\n",
            "Iteration started\n",
            "Epoch : 024  Train Loss : -0.23659 Val Loss : 0.40257   BatchID= 0   Val_AUC=0.4989   Best_Val_AUC=0.5117\n",
            "Epoch : 24\n",
            "Iteration started\n",
            "Epoch : 025  Train Loss : 0.09709 Val Loss : 0.46206   BatchID= 0   Val_AUC=0.4967   Best_Val_AUC=0.5117\n",
            "Epoch : 25\n",
            "Iteration started\n",
            "Epoch : 026  Train Loss : 0.01527 Val Loss : 0.54786   BatchID= 0   Val_AUC=0.5020   Best_Val_AUC=0.5117\n",
            "Epoch : 26\n",
            "Iteration started\n",
            "Epoch : 027  Train Loss : 0.10417 Val Loss : 0.64513   BatchID= 0   Val_AUC=0.5075   Best_Val_AUC=0.5117\n",
            "Epoch : 27\n",
            "Iteration started\n",
            "Epoch : 028  Train Loss : 0.13060 Val Loss : 0.72928   BatchID= 0   Val_AUC=0.5014   Best_Val_AUC=0.5117\n",
            "Epoch : 28\n",
            "Iteration started\n",
            "Epoch : 029  Train Loss : -0.05657 Val Loss : 0.82508   BatchID= 0   Val_AUC=0.5084   Best_Val_AUC=0.5117\n",
            "Epoch : 29\n",
            "Iteration started\n",
            "Epoch : 030  Train Loss : 0.10275 Val Loss : 0.91367   BatchID= 0   Val_AUC=0.5079   Best_Val_AUC=0.5117\n",
            "Epoch : 30\n",
            "Iteration started\n",
            "Epoch : 031  Train Loss : 0.10213 Val Loss : 0.98082   BatchID= 0   Val_AUC=0.5093   Best_Val_AUC=0.5117\n",
            "Epoch : 31\n",
            "Iteration started\n",
            "Epoch : 032  Train Loss : 0.12444 Val Loss : 1.07470   BatchID= 0   Val_AUC=0.5131   Best_Val_AUC=0.5131\n",
            "Epoch : 32\n",
            "Iteration started\n",
            "Epoch : 033  Train Loss : 0.12478 Val Loss : 1.16361   BatchID= 0   Val_AUC=0.5140   Best_Val_AUC=0.5140\n",
            "Epoch : 33\n",
            "Iteration started\n",
            "Epoch : 034  Train Loss : 0.10188 Val Loss : 1.25877   BatchID= 0   Val_AUC=0.5120   Best_Val_AUC=0.5140\n",
            "Epoch : 34\n",
            "Iteration started\n",
            "Epoch : 035  Train Loss : 0.06641 Val Loss : 1.32957   BatchID= 0   Val_AUC=0.5069   Best_Val_AUC=0.5140\n",
            "Epoch : 35\n",
            "Iteration started\n",
            "Epoch : 036  Train Loss : 0.12125 Val Loss : 1.37526   BatchID= 0   Val_AUC=0.5156   Best_Val_AUC=0.5156\n",
            "Epoch : 36\n",
            "Iteration started\n",
            "Epoch : 037  Train Loss : 0.09656 Val Loss : 1.45926   BatchID= 0   Val_AUC=0.5160   Best_Val_AUC=0.5160\n",
            "Epoch : 37\n",
            "Iteration started\n",
            "Epoch : 038  Train Loss : 0.06340 Val Loss : 1.50696   BatchID= 0   Val_AUC=0.5080   Best_Val_AUC=0.5160\n",
            "Epoch : 38\n",
            "Iteration started\n",
            "Epoch : 039  Train Loss : 0.12125 Val Loss : 1.57667   BatchID= 0   Val_AUC=0.5143   Best_Val_AUC=0.5160\n",
            "Epoch : 39\n",
            "Iteration started\n",
            "Epoch : 040  Train Loss : 0.12137 Val Loss : 1.62155   BatchID= 0   Val_AUC=0.5129   Best_Val_AUC=0.5160\n",
            "Epoch : 40\n",
            "Iteration started\n",
            "Epoch : 041  Train Loss : 0.10184 Val Loss : 1.73899   BatchID= 0   Val_AUC=0.5153   Best_Val_AUC=0.5160\n",
            "Epoch : 41\n",
            "Iteration started\n",
            "Epoch : 042  Train Loss : 0.12077 Val Loss : 1.74094   BatchID= 0   Val_AUC=0.5129   Best_Val_AUC=0.5160\n",
            "Epoch : 42\n",
            "Iteration started\n",
            "Epoch : 043  Train Loss : 0.13059 Val Loss : 1.80816   BatchID= 0   Val_AUC=0.5110   Best_Val_AUC=0.5160\n",
            "Epoch : 43\n",
            "Iteration started\n",
            "Epoch : 044  Train Loss : 0.06438 Val Loss : 1.92658   BatchID= 0   Val_AUC=0.5144   Best_Val_AUC=0.5160\n",
            "Epoch : 44\n",
            "Iteration started\n",
            "Epoch : 045  Train Loss : 0.06353 Val Loss : 1.98344   BatchID= 0   Val_AUC=0.5172   Best_Val_AUC=0.5172\n",
            "Epoch : 45\n",
            "Iteration started\n",
            "Epoch : 046  Train Loss : 0.12301 Val Loss : 2.03990   BatchID= 0   Val_AUC=0.5166   Best_Val_AUC=0.5172\n",
            "Epoch : 46\n",
            "Iteration started\n",
            "Epoch : 047  Train Loss : 0.09619 Val Loss : 2.09139   BatchID= 0   Val_AUC=0.5117   Best_Val_AUC=0.5172\n",
            "Epoch : 47\n",
            "Iteration started\n",
            "Epoch : 048  Train Loss : 0.05588 Val Loss : 2.09242   BatchID= 0   Val_AUC=0.5144   Best_Val_AUC=0.5172\n",
            "Epoch : 48\n",
            "Iteration started\n",
            "Epoch : 049  Train Loss : 0.01096 Val Loss : 2.18472   BatchID= 0   Val_AUC=0.5176   Best_Val_AUC=0.5176\n",
            "Epoch : 49\n",
            "Iteration started\n",
            "Epoch : 050  Train Loss : 0.05594 Val Loss : 2.14325   BatchID= 0   Val_AUC=0.5204   Best_Val_AUC=0.5204\n",
            "Epoch : 50\n",
            "Iteration started\n",
            "Epoch : 051  Train Loss : -0.05827 Val Loss : 2.20850   BatchID= 0   Val_AUC=0.5244   Best_Val_AUC=0.5244\n",
            "Epoch : 51\n",
            "Iteration started\n",
            "Epoch : 052  Train Loss : 0.13034 Val Loss : 2.27799   BatchID= 0   Val_AUC=0.5235   Best_Val_AUC=0.5244\n",
            "Epoch : 52\n",
            "Iteration started\n",
            "Epoch : 053  Train Loss : 0.12965 Val Loss : 2.31888   BatchID= 0   Val_AUC=0.5244   Best_Val_AUC=0.5244\n",
            "Epoch : 53\n",
            "Iteration started\n",
            "Epoch : 054  Train Loss : 0.10104 Val Loss : 2.39054   BatchID= 0   Val_AUC=0.5214   Best_Val_AUC=0.5244\n",
            "Epoch : 54\n",
            "Iteration started\n",
            "Epoch : 055  Train Loss : -0.49131 Val Loss : 2.46798   BatchID= 0   Val_AUC=0.5176   Best_Val_AUC=0.5244\n",
            "Epoch : 55\n",
            "Iteration started\n",
            "Epoch : 056  Train Loss : 0.13036 Val Loss : 2.51576   BatchID= 0   Val_AUC=0.5123   Best_Val_AUC=0.5244\n",
            "Epoch : 56\n",
            "Iteration started\n",
            "Epoch : 057  Train Loss : 0.12060 Val Loss : 2.56086   BatchID= 0   Val_AUC=0.5118   Best_Val_AUC=0.5244\n",
            "Epoch : 57\n",
            "Iteration started\n",
            "Epoch : 058  Train Loss : 0.06216 Val Loss : 2.58002   BatchID= 0   Val_AUC=0.5139   Best_Val_AUC=0.5244\n",
            "Epoch : 58\n",
            "Iteration started\n",
            "Epoch : 059  Train Loss : 0.10058 Val Loss : 2.63789   BatchID= 0   Val_AUC=0.5137   Best_Val_AUC=0.5244\n",
            "Epoch : 59\n",
            "Iteration started\n",
            "Epoch : 060  Train Loss : 0.12121 Val Loss : 2.59531   BatchID= 0   Val_AUC=0.5185   Best_Val_AUC=0.5244\n",
            "Epoch : 60\n",
            "Iteration started\n",
            "Epoch : 061  Train Loss : 0.06227 Val Loss : 2.63132   BatchID= 0   Val_AUC=0.5263   Best_Val_AUC=0.5263\n",
            "Epoch : 61\n",
            "Iteration started\n",
            "Epoch : 062  Train Loss : 0.12104 Val Loss : 2.62202   BatchID= 0   Val_AUC=0.5214   Best_Val_AUC=0.5263\n",
            "Epoch : 62\n",
            "Iteration started\n",
            "Epoch : 063  Train Loss : 0.12384 Val Loss : 2.64167   BatchID= 0   Val_AUC=0.5232   Best_Val_AUC=0.5263\n",
            "Epoch : 63\n",
            "Iteration started\n",
            "Epoch : 064  Train Loss : -0.05976 Val Loss : 2.68536   BatchID= 0   Val_AUC=0.5252   Best_Val_AUC=0.5263\n",
            "Epoch : 64\n",
            "Iteration started\n",
            "Epoch : 065  Train Loss : 0.06204 Val Loss : 2.73059   BatchID= 0   Val_AUC=0.5252   Best_Val_AUC=0.5263\n",
            "Epoch : 65\n",
            "Iteration started\n",
            "Epoch : 066  Train Loss : 0.12067 Val Loss : 2.80084   BatchID= 0   Val_AUC=0.5210   Best_Val_AUC=0.5263\n",
            "Epoch : 66\n",
            "Iteration started\n",
            "Epoch : 067  Train Loss : 0.10120 Val Loss : 2.83198   BatchID= 0   Val_AUC=0.5280   Best_Val_AUC=0.5280\n",
            "Epoch : 67\n",
            "Iteration started\n",
            "Epoch : 068  Train Loss : 0.09626 Val Loss : 2.85634   BatchID= 0   Val_AUC=0.5224   Best_Val_AUC=0.5280\n",
            "Epoch : 68\n",
            "Iteration started\n",
            "Epoch : 069  Train Loss : 0.12102 Val Loss : 2.90074   BatchID= 0   Val_AUC=0.5212   Best_Val_AUC=0.5280\n",
            "Epoch : 69\n",
            "Iteration started\n",
            "Epoch : 070  Train Loss : 0.12914 Val Loss : 2.89839   BatchID= 0   Val_AUC=0.5250   Best_Val_AUC=0.5280\n",
            "Epoch : 70\n",
            "Iteration started\n",
            "Epoch : 071  Train Loss : 0.00780 Val Loss : 2.88397   BatchID= 0   Val_AUC=0.5261   Best_Val_AUC=0.5280\n",
            "Epoch : 71\n",
            "Iteration started\n",
            "Epoch : 072  Train Loss : 0.09572 Val Loss : 2.92638   BatchID= 0   Val_AUC=0.5206   Best_Val_AUC=0.5280\n",
            "Epoch : 72\n",
            "Iteration started\n",
            "Epoch : 073  Train Loss : 0.12035 Val Loss : 2.95045   BatchID= 0   Val_AUC=0.5257   Best_Val_AUC=0.5280\n",
            "Epoch : 73\n",
            "Iteration started\n",
            "Epoch : 074  Train Loss : 0.12027 Val Loss : 2.99071   BatchID= 0   Val_AUC=0.5261   Best_Val_AUC=0.5280\n",
            "Epoch : 74\n",
            "Iteration started\n",
            "Epoch : 075  Train Loss : 0.12305 Val Loss : 3.07130   BatchID= 0   Val_AUC=0.5225   Best_Val_AUC=0.5280\n",
            "Epoch : 75\n",
            "Iteration started\n",
            "Epoch : 076  Train Loss : 0.09599 Val Loss : 3.06132   BatchID= 0   Val_AUC=0.5187   Best_Val_AUC=0.5280\n",
            "Epoch : 76\n",
            "Iteration started\n",
            "Epoch : 077  Train Loss : 0.09608 Val Loss : 3.05635   BatchID= 0   Val_AUC=0.5206   Best_Val_AUC=0.5280\n",
            "Epoch : 77\n",
            "Iteration started\n",
            "Epoch : 078  Train Loss : 0.06253 Val Loss : 2.98888   BatchID= 0   Val_AUC=0.5225   Best_Val_AUC=0.5280\n",
            "Epoch : 78\n",
            "Iteration started\n",
            "Epoch : 079  Train Loss : 0.10028 Val Loss : 3.03205   BatchID= 0   Val_AUC=0.5299   Best_Val_AUC=0.5299\n",
            "Epoch : 79\n",
            "Iteration started\n",
            "Epoch : 080  Train Loss : 0.06259 Val Loss : 3.03693   BatchID= 0   Val_AUC=0.5228   Best_Val_AUC=0.5299\n",
            "Epoch : 80\n",
            "Iteration started\n",
            "Epoch : 081  Train Loss : 0.10143 Val Loss : 3.00363   BatchID= 0   Val_AUC=0.5236   Best_Val_AUC=0.5299\n",
            "Epoch : 81\n",
            "Iteration started\n",
            "Epoch : 082  Train Loss : 0.06337 Val Loss : 2.92688   BatchID= 0   Val_AUC=0.5226   Best_Val_AUC=0.5299\n",
            "Epoch : 82\n",
            "Iteration started\n",
            "Epoch : 083  Train Loss : 0.10046 Val Loss : 2.90651   BatchID= 0   Val_AUC=0.5297   Best_Val_AUC=0.5299\n",
            "Epoch : 83\n",
            "Iteration started\n",
            "Epoch : 084  Train Loss : 0.01151 Val Loss : 2.89578   BatchID= 0   Val_AUC=0.5293   Best_Val_AUC=0.5299\n",
            "Epoch : 84\n",
            "Iteration started\n",
            "Epoch : 085  Train Loss : -0.06104 Val Loss : 2.92413   BatchID= 0   Val_AUC=0.5267   Best_Val_AUC=0.5299\n",
            "Epoch : 85\n",
            "Iteration started\n",
            "Epoch : 086  Train Loss : 0.09633 Val Loss : 2.92991   BatchID= 0   Val_AUC=0.5250   Best_Val_AUC=0.5299\n",
            "Epoch : 86\n",
            "Iteration started\n",
            "Epoch : 087  Train Loss : 0.00000 Val Loss : 2.94178   BatchID= 0   Val_AUC=0.5283   Best_Val_AUC=0.5299\n",
            "Epoch : 87\n",
            "Iteration started\n",
            "Epoch : 088  Train Loss : 0.12224 Val Loss : 2.94993   BatchID= 0   Val_AUC=0.5256   Best_Val_AUC=0.5299\n",
            "Epoch : 88\n",
            "Iteration started\n",
            "Epoch : 089  Train Loss : 0.01021 Val Loss : 2.94034   BatchID= 0   Val_AUC=0.5256   Best_Val_AUC=0.5299\n",
            "Epoch : 89\n",
            "Iteration started\n",
            "Epoch : 090  Train Loss : 0.00000 Val Loss : 2.95964   BatchID= 0   Val_AUC=0.5235   Best_Val_AUC=0.5299\n",
            "Epoch : 90\n",
            "Iteration started\n",
            "Epoch : 091  Train Loss : 0.12352 Val Loss : 2.97645   BatchID= 0   Val_AUC=0.5196   Best_Val_AUC=0.5299\n",
            "Epoch : 91\n",
            "Iteration started\n",
            "Epoch : 092  Train Loss : 0.12931 Val Loss : 2.99451   BatchID= 0   Val_AUC=0.5241   Best_Val_AUC=0.5299\n",
            "Epoch : 92\n",
            "Iteration started\n",
            "Epoch : 093  Train Loss : 0.12256 Val Loss : 2.99833   BatchID= 0   Val_AUC=0.5242   Best_Val_AUC=0.5299\n",
            "Epoch : 93\n",
            "Iteration started\n",
            "Epoch : 094  Train Loss : 0.12304 Val Loss : 2.99579   BatchID= 0   Val_AUC=0.5264   Best_Val_AUC=0.5299\n",
            "Epoch : 94\n",
            "Iteration started\n",
            "Epoch : 095  Train Loss : 0.12298 Val Loss : 2.95756   BatchID= 0   Val_AUC=0.5290   Best_Val_AUC=0.5299\n",
            "Epoch : 95\n",
            "Iteration started\n",
            "Epoch : 096  Train Loss : 0.12343 Val Loss : 2.94656   BatchID= 0   Val_AUC=0.5263   Best_Val_AUC=0.5299\n",
            "Epoch : 96\n",
            "Iteration started\n",
            "Epoch : 097  Train Loss : 0.12303 Val Loss : 2.91411   BatchID= 0   Val_AUC=0.5264   Best_Val_AUC=0.5299\n",
            "Epoch : 97\n",
            "Iteration started\n",
            "Epoch : 098  Train Loss : 0.12101 Val Loss : 2.93534   BatchID= 0   Val_AUC=0.5217   Best_Val_AUC=0.5299\n",
            "Epoch : 98\n",
            "Iteration started\n",
            "Epoch : 099  Train Loss : 0.05604 Val Loss : 2.95369   BatchID= 0   Val_AUC=0.5222   Best_Val_AUC=0.5299\n",
            "Epoch : 99\n",
            "Iteration started\n",
            "Epoch : 100  Train Loss : 0.12965 Val Loss : 2.93572   BatchID= 0   Val_AUC=0.5234   Best_Val_AUC=0.5299\n",
            "Epoch : 100\n",
            "Iteration started\n",
            "Epoch : 101  Train Loss : 0.12418 Val Loss : 2.93821   BatchID= 0   Val_AUC=0.5277   Best_Val_AUC=0.5299\n",
            "Epoch : 101\n",
            "Iteration started\n",
            "Epoch : 102  Train Loss : 0.09614 Val Loss : 2.90338   BatchID= 0   Val_AUC=0.5246   Best_Val_AUC=0.5299\n",
            "Epoch : 102\n",
            "Iteration started\n",
            "Epoch : 103  Train Loss : 0.12087 Val Loss : 2.88325   BatchID= 0   Val_AUC=0.5263   Best_Val_AUC=0.5299\n",
            "Epoch : 103\n",
            "Iteration started\n",
            "Epoch : 104  Train Loss : -0.06079 Val Loss : 2.89311   BatchID= 0   Val_AUC=0.5280   Best_Val_AUC=0.5299\n",
            "Epoch : 104\n",
            "Iteration started\n",
            "Epoch : 105  Train Loss : 0.13109 Val Loss : 2.75136   BatchID= 0   Val_AUC=0.5267   Best_Val_AUC=0.5299\n",
            "Epoch : 105\n",
            "Iteration started\n",
            "Epoch : 106  Train Loss : 0.12954 Val Loss : 2.77499   BatchID= 0   Val_AUC=0.5270   Best_Val_AUC=0.5299\n",
            "Epoch : 106\n",
            "Iteration started\n",
            "Epoch : 107  Train Loss : 0.10102 Val Loss : 2.84933   BatchID= 0   Val_AUC=0.5270   Best_Val_AUC=0.5299\n",
            "Epoch : 107\n",
            "Iteration started\n",
            "Epoch : 108  Train Loss : 0.12264 Val Loss : 2.84754   BatchID= 0   Val_AUC=0.5258   Best_Val_AUC=0.5299\n",
            "Epoch : 108\n",
            "Iteration started\n",
            "Epoch : 109  Train Loss : -0.24266 Val Loss : 2.88986   BatchID= 0   Val_AUC=0.5260   Best_Val_AUC=0.5299\n",
            "Epoch : 109\n",
            "Iteration started\n",
            "Epoch : 110  Train Loss : -0.06076 Val Loss : 2.96684   BatchID= 0   Val_AUC=0.5256   Best_Val_AUC=0.5299\n",
            "Epoch : 110\n",
            "Iteration started\n",
            "Epoch : 111  Train Loss : 0.05559 Val Loss : 2.94967   BatchID= 0   Val_AUC=0.5243   Best_Val_AUC=0.5299\n",
            "Epoch : 111\n",
            "Iteration started\n",
            "Epoch : 112  Train Loss : 0.12371 Val Loss : 2.94350   BatchID= 0   Val_AUC=0.5267   Best_Val_AUC=0.5299\n",
            "Epoch : 112\n",
            "Iteration started\n",
            "Epoch : 113  Train Loss : 0.12273 Val Loss : 2.92035   BatchID= 0   Val_AUC=0.5317   Best_Val_AUC=0.5317\n",
            "Epoch : 113\n",
            "Iteration started\n",
            "Epoch : 114  Train Loss : 0.12036 Val Loss : 2.91455   BatchID= 0   Val_AUC=0.5328   Best_Val_AUC=0.5328\n",
            "Epoch : 114\n",
            "Iteration started\n",
            "Epoch : 115  Train Loss : 0.12910 Val Loss : 2.93776   BatchID= 0   Val_AUC=0.5325   Best_Val_AUC=0.5328\n",
            "Epoch : 115\n",
            "Iteration started\n",
            "Epoch : 116  Train Loss : 0.10027 Val Loss : 2.97081   BatchID= 0   Val_AUC=0.5275   Best_Val_AUC=0.5328\n",
            "Epoch : 116\n",
            "Iteration started\n",
            "Epoch : 117  Train Loss : -0.24265 Val Loss : 2.96120   BatchID= 0   Val_AUC=0.5322   Best_Val_AUC=0.5328\n",
            "Epoch : 117\n",
            "Iteration started\n",
            "Epoch : 118  Train Loss : 0.12385 Val Loss : 2.93398   BatchID= 0   Val_AUC=0.5330   Best_Val_AUC=0.5330\n",
            "Epoch : 118\n",
            "Iteration started\n",
            "Epoch : 119  Train Loss : 0.12936 Val Loss : 2.88857   BatchID= 0   Val_AUC=0.5310   Best_Val_AUC=0.5330\n",
            "Epoch : 119\n",
            "Iteration started\n",
            "Epoch : 120  Train Loss : 0.00881 Val Loss : 2.91690   BatchID= 0   Val_AUC=0.5241   Best_Val_AUC=0.5330\n",
            "Epoch : 120\n",
            "Iteration started\n",
            "Epoch : 121  Train Loss : 0.12870 Val Loss : 2.96380   BatchID= 0   Val_AUC=0.5212   Best_Val_AUC=0.5330\n",
            "Epoch : 121\n",
            "Iteration started\n",
            "Epoch : 122  Train Loss : 0.12337 Val Loss : 2.94103   BatchID= 0   Val_AUC=0.5216   Best_Val_AUC=0.5330\n",
            "Epoch : 122\n",
            "Iteration started\n",
            "Epoch : 123  Train Loss : 0.12319 Val Loss : 2.91596   BatchID= 0   Val_AUC=0.5209   Best_Val_AUC=0.5330\n",
            "Epoch : 123\n",
            "Iteration started\n",
            "Epoch : 124  Train Loss : -0.49096 Val Loss : 2.95902   BatchID= 0   Val_AUC=0.5244   Best_Val_AUC=0.5330\n",
            "Epoch : 124\n",
            "Iteration started\n",
            "Epoch : 125  Train Loss : 0.12007 Val Loss : 2.96762   BatchID= 0   Val_AUC=0.5206   Best_Val_AUC=0.5330\n",
            "Epoch : 125\n",
            "Iteration started\n",
            "Epoch : 126  Train Loss : 0.12954 Val Loss : 3.02192   BatchID= 0   Val_AUC=0.5201   Best_Val_AUC=0.5330\n",
            "Epoch : 126\n",
            "Iteration started\n",
            "Epoch : 127  Train Loss : 0.00000 Val Loss : 3.03084   BatchID= 0   Val_AUC=0.5231   Best_Val_AUC=0.5330\n",
            "Epoch : 127\n",
            "Iteration started\n",
            "Epoch : 128  Train Loss : 0.13089 Val Loss : 3.04712   BatchID= 0   Val_AUC=0.5205   Best_Val_AUC=0.5330\n",
            "Epoch : 128\n",
            "Iteration started\n",
            "Epoch : 129  Train Loss : 0.09589 Val Loss : 3.02455   BatchID= 0   Val_AUC=0.5231   Best_Val_AUC=0.5330\n",
            "Epoch : 129\n",
            "Iteration started\n",
            "Epoch : 130  Train Loss : 0.12229 Val Loss : 3.13127   BatchID= 0   Val_AUC=0.5229   Best_Val_AUC=0.5330\n",
            "Epoch : 130\n",
            "Iteration started\n",
            "Epoch : 131  Train Loss : 0.00857 Val Loss : 3.14543   BatchID= 0   Val_AUC=0.5215   Best_Val_AUC=0.5330\n",
            "Epoch : 131\n",
            "Iteration started\n",
            "Epoch : 132  Train Loss : 0.05588 Val Loss : 3.10032   BatchID= 0   Val_AUC=0.5229   Best_Val_AUC=0.5330\n",
            "Epoch : 132\n",
            "Iteration started\n",
            "Epoch : 133  Train Loss : 0.12269 Val Loss : 3.13664   BatchID= 0   Val_AUC=0.5175   Best_Val_AUC=0.5330\n",
            "Epoch : 133\n",
            "Iteration started\n",
            "Epoch : 134  Train Loss : -0.06063 Val Loss : 3.14507   BatchID= 0   Val_AUC=0.5186   Best_Val_AUC=0.5330\n",
            "Epoch : 134\n",
            "Iteration started\n",
            "Epoch : 135  Train Loss : 0.06585 Val Loss : 3.05037   BatchID= 0   Val_AUC=0.5274   Best_Val_AUC=0.5330\n",
            "Epoch : 135\n",
            "Iteration started\n",
            "Epoch : 136  Train Loss : 0.01124 Val Loss : 2.99113   BatchID= 0   Val_AUC=0.5191   Best_Val_AUC=0.5330\n",
            "Epoch : 136\n",
            "Iteration started\n",
            "Epoch : 137  Train Loss : 0.13031 Val Loss : 2.97073   BatchID= 0   Val_AUC=0.5147   Best_Val_AUC=0.5330\n",
            "Epoch : 137\n",
            "Iteration started\n",
            "Epoch : 138  Train Loss : 0.12946 Val Loss : 2.94417   BatchID= 0   Val_AUC=0.5168   Best_Val_AUC=0.5330\n",
            "Epoch : 138\n",
            "Iteration started\n",
            "Epoch : 139  Train Loss : 0.09574 Val Loss : 2.89450   BatchID= 0   Val_AUC=0.5161   Best_Val_AUC=0.5330\n",
            "Epoch : 139\n",
            "Iteration started\n",
            "Epoch : 140  Train Loss : 0.06276 Val Loss : 2.89915   BatchID= 0   Val_AUC=0.5188   Best_Val_AUC=0.5330\n",
            "Epoch : 140\n",
            "Iteration started\n",
            "Epoch : 141  Train Loss : 0.12069 Val Loss : 2.89411   BatchID= 0   Val_AUC=0.5219   Best_Val_AUC=0.5330\n",
            "Epoch : 141\n",
            "Iteration started\n",
            "Epoch : 142  Train Loss : -0.14205 Val Loss : 2.87850   BatchID= 0   Val_AUC=0.5246   Best_Val_AUC=0.5330\n",
            "Epoch : 142\n",
            "Iteration started\n",
            "Epoch : 143  Train Loss : -0.05870 Val Loss : 2.91219   BatchID= 0   Val_AUC=0.5113   Best_Val_AUC=0.5330\n",
            "Epoch : 143\n",
            "Iteration started\n",
            "Epoch : 144  Train Loss : 0.09609 Val Loss : 2.87127   BatchID= 0   Val_AUC=0.5087   Best_Val_AUC=0.5330\n",
            "Epoch : 144\n",
            "Iteration started\n",
            "Epoch : 145  Train Loss : 0.10262 Val Loss : 2.77025   BatchID= 0   Val_AUC=0.5083   Best_Val_AUC=0.5330\n",
            "Epoch : 145\n",
            "Iteration started\n",
            "Epoch : 146  Train Loss : 0.06152 Val Loss : 2.85091   BatchID= 0   Val_AUC=0.5068   Best_Val_AUC=0.5330\n",
            "Epoch : 146\n",
            "Iteration started\n",
            "Epoch : 147  Train Loss : -0.14444 Val Loss : 2.91197   BatchID= 0   Val_AUC=0.5054   Best_Val_AUC=0.5330\n",
            "Epoch : 147\n",
            "Iteration started\n",
            "Epoch : 148  Train Loss : 0.12910 Val Loss : 2.93744   BatchID= 0   Val_AUC=0.5027   Best_Val_AUC=0.5330\n",
            "Epoch : 148\n",
            "Iteration started\n",
            "Epoch : 149  Train Loss : 0.12200 Val Loss : 2.99311   BatchID= 0   Val_AUC=0.5072   Best_Val_AUC=0.5330\n",
            "Epoch : 149\n",
            "Iteration started\n",
            "Epoch : 150  Train Loss : -0.14222 Val Loss : 2.96821   BatchID= 0   Val_AUC=0.5107   Best_Val_AUC=0.5330\n",
            "Epoch : 150\n",
            "Iteration started\n",
            "Epoch : 151  Train Loss : 0.09897 Val Loss : 3.02457   BatchID= 0   Val_AUC=0.5064   Best_Val_AUC=0.5330\n",
            "Epoch : 151\n",
            "Iteration started\n",
            "Epoch : 152  Train Loss : -0.05488 Val Loss : 2.96487   BatchID= 0   Val_AUC=0.5123   Best_Val_AUC=0.5330\n",
            "Epoch : 152\n",
            "Iteration started\n",
            "Epoch : 153  Train Loss : 0.12225 Val Loss : 2.98199   BatchID= 0   Val_AUC=0.5094   Best_Val_AUC=0.5330\n",
            "Epoch : 153\n",
            "Iteration started\n",
            "Epoch : 154  Train Loss : -0.06097 Val Loss : 3.02648   BatchID= 0   Val_AUC=0.5132   Best_Val_AUC=0.5330\n",
            "Epoch : 154\n",
            "Iteration started\n",
            "Epoch : 155  Train Loss : -0.64187 Val Loss : 3.22696   BatchID= 0   Val_AUC=0.5192   Best_Val_AUC=0.5330\n",
            "Epoch : 155\n",
            "Iteration started\n",
            "Epoch : 156  Train Loss : 0.12976 Val Loss : 3.20950   BatchID= 0   Val_AUC=0.5229   Best_Val_AUC=0.5330\n",
            "Epoch : 156\n",
            "Iteration started\n",
            "Epoch : 157  Train Loss : 0.12166 Val Loss : 3.22717   BatchID= 0   Val_AUC=0.5221   Best_Val_AUC=0.5330\n",
            "Epoch : 157\n",
            "Iteration started\n",
            "Epoch : 158  Train Loss : 0.06242 Val Loss : 3.20032   BatchID= 0   Val_AUC=0.5236   Best_Val_AUC=0.5330\n",
            "Epoch : 158\n",
            "Iteration started\n",
            "Epoch : 159  Train Loss : 0.06114 Val Loss : 3.23545   BatchID= 0   Val_AUC=0.5205   Best_Val_AUC=0.5330\n",
            "Epoch : 159\n",
            "Iteration started\n",
            "Epoch : 160  Train Loss : 0.09869 Val Loss : 3.27147   BatchID= 0   Val_AUC=0.5254   Best_Val_AUC=0.5330\n",
            "Epoch : 160\n",
            "Iteration started\n",
            "Epoch : 161  Train Loss : 0.09913 Val Loss : 3.31830   BatchID= 0   Val_AUC=0.5201   Best_Val_AUC=0.5330\n",
            "Epoch : 161\n",
            "Iteration started\n",
            "Epoch : 162  Train Loss : 0.12963 Val Loss : 3.28319   BatchID= 0   Val_AUC=0.5180   Best_Val_AUC=0.5330\n",
            "Epoch : 162\n",
            "Iteration started\n",
            "Epoch : 163  Train Loss : 0.12875 Val Loss : 3.26745   BatchID= 0   Val_AUC=0.5197   Best_Val_AUC=0.5330\n",
            "Epoch : 163\n",
            "Iteration started\n",
            "Epoch : 164  Train Loss : 0.12002 Val Loss : 3.25188   BatchID= 0   Val_AUC=0.5170   Best_Val_AUC=0.5330\n",
            "Epoch : 164\n",
            "Iteration started\n",
            "Epoch : 165  Train Loss : 0.00796 Val Loss : 3.33521   BatchID= 0   Val_AUC=0.5217   Best_Val_AUC=0.5330\n",
            "Epoch : 165\n",
            "Iteration started\n",
            "Epoch : 166  Train Loss : 0.12111 Val Loss : 3.30844   BatchID= 0   Val_AUC=0.5119   Best_Val_AUC=0.5330\n",
            "Epoch : 166\n",
            "Iteration started\n",
            "Epoch : 167  Train Loss : -0.06136 Val Loss : 3.30851   BatchID= 0   Val_AUC=0.5100   Best_Val_AUC=0.5330\n",
            "Epoch : 167\n",
            "Iteration started\n",
            "Epoch : 168  Train Loss : 0.09892 Val Loss : 3.34244   BatchID= 0   Val_AUC=0.5096   Best_Val_AUC=0.5330\n",
            "Epoch : 168\n",
            "Iteration started\n",
            "Epoch : 169  Train Loss : 0.12155 Val Loss : 3.14830   BatchID= 0   Val_AUC=0.5127   Best_Val_AUC=0.5330\n",
            "Epoch : 169\n",
            "Iteration started\n",
            "Epoch : 170  Train Loss : -0.14321 Val Loss : 3.12460   BatchID= 0   Val_AUC=0.5072   Best_Val_AUC=0.5330\n",
            "Epoch : 170\n",
            "Iteration started\n",
            "Epoch : 171  Train Loss : 0.11992 Val Loss : 3.12958   BatchID= 0   Val_AUC=0.5121   Best_Val_AUC=0.5330\n",
            "Epoch : 171\n",
            "Iteration started\n",
            "Epoch : 172  Train Loss : 0.12261 Val Loss : 3.12627   BatchID= 0   Val_AUC=0.5121   Best_Val_AUC=0.5330\n",
            "Epoch : 172\n",
            "Iteration started\n",
            "Epoch : 173  Train Loss : 0.00860 Val Loss : 3.15868   BatchID= 0   Val_AUC=0.5156   Best_Val_AUC=0.5330\n",
            "Epoch : 173\n",
            "Iteration started\n",
            "Epoch : 174  Train Loss : 0.12208 Val Loss : 3.19523   BatchID= 0   Val_AUC=0.5103   Best_Val_AUC=0.5330\n",
            "Epoch : 174\n",
            "Iteration started\n",
            "Epoch : 175  Train Loss : 0.00000 Val Loss : 3.24456   BatchID= 0   Val_AUC=0.5127   Best_Val_AUC=0.5330\n",
            "Epoch : 175\n",
            "Iteration started\n",
            "Epoch : 176  Train Loss : 0.09562 Val Loss : 3.26241   BatchID= 0   Val_AUC=0.5055   Best_Val_AUC=0.5330\n",
            "Epoch : 176\n",
            "Iteration started\n",
            "Epoch : 177  Train Loss : 0.12041 Val Loss : 3.23880   BatchID= 0   Val_AUC=0.5074   Best_Val_AUC=0.5330\n",
            "Epoch : 177\n",
            "Iteration started\n",
            "Epoch : 178  Train Loss : 0.12269 Val Loss : 3.24917   BatchID= 0   Val_AUC=0.5114   Best_Val_AUC=0.5330\n",
            "Epoch : 178\n",
            "Iteration started\n",
            "Epoch : 179  Train Loss : -0.06111 Val Loss : 3.29741   BatchID= 0   Val_AUC=0.5017   Best_Val_AUC=0.5330\n",
            "Epoch : 179\n",
            "Iteration started\n",
            "Epoch : 180  Train Loss : 0.12080 Val Loss : 3.27072   BatchID= 0   Val_AUC=0.5037   Best_Val_AUC=0.5330\n",
            "Epoch : 180\n",
            "Iteration started\n",
            "Epoch : 181  Train Loss : 0.12049 Val Loss : 3.26253   BatchID= 0   Val_AUC=0.5052   Best_Val_AUC=0.5330\n",
            "Epoch : 181\n",
            "Iteration started\n",
            "Epoch : 182  Train Loss : 0.12975 Val Loss : 3.20583   BatchID= 0   Val_AUC=0.5055   Best_Val_AUC=0.5330\n",
            "Epoch : 182\n",
            "Iteration started\n",
            "Epoch : 183  Train Loss : 0.12387 Val Loss : 3.15700   BatchID= 0   Val_AUC=0.4991   Best_Val_AUC=0.5330\n",
            "Epoch : 183\n",
            "Iteration started\n",
            "Epoch : 184  Train Loss : 0.10041 Val Loss : 3.13607   BatchID= 0   Val_AUC=0.5014   Best_Val_AUC=0.5330\n",
            "Epoch : 184\n",
            "Iteration started\n",
            "Epoch : 185  Train Loss : 0.05589 Val Loss : 3.06936   BatchID= 0   Val_AUC=0.5045   Best_Val_AUC=0.5330\n",
            "Epoch : 185\n",
            "Iteration started\n",
            "Epoch : 186  Train Loss : -0.14540 Val Loss : 3.12157   BatchID= 0   Val_AUC=0.5001   Best_Val_AUC=0.5330\n",
            "Epoch : 186\n",
            "Iteration started\n",
            "Epoch : 187  Train Loss : 0.12258 Val Loss : 3.13154   BatchID= 0   Val_AUC=0.5029   Best_Val_AUC=0.5330\n",
            "Epoch : 187\n",
            "Iteration started\n",
            "Epoch : 188  Train Loss : 0.10425 Val Loss : 2.97940   BatchID= 0   Val_AUC=0.4991   Best_Val_AUC=0.5330\n",
            "Epoch : 188\n",
            "Iteration started\n",
            "Epoch : 189  Train Loss : 0.06428 Val Loss : 2.99721   BatchID= 0   Val_AUC=0.5071   Best_Val_AUC=0.5330\n",
            "Epoch : 189\n",
            "Iteration started\n",
            "Epoch : 190  Train Loss : 0.12978 Val Loss : 2.98100   BatchID= 0   Val_AUC=0.5093   Best_Val_AUC=0.5330\n",
            "Epoch : 190\n",
            "Iteration started\n",
            "Epoch : 191  Train Loss : 0.12057 Val Loss : 2.98300   BatchID= 0   Val_AUC=0.5046   Best_Val_AUC=0.5330\n",
            "Epoch : 191\n",
            "Iteration started\n",
            "Epoch : 192  Train Loss : 0.01052 Val Loss : 2.99634   BatchID= 0   Val_AUC=0.5014   Best_Val_AUC=0.5330\n",
            "Epoch : 192\n",
            "Iteration started\n",
            "Epoch : 193  Train Loss : -0.05939 Val Loss : 3.08306   BatchID= 0   Val_AUC=0.5101   Best_Val_AUC=0.5330\n",
            "Epoch : 193\n",
            "Iteration started\n",
            "Epoch : 194  Train Loss : -0.05950 Val Loss : 3.08309   BatchID= 0   Val_AUC=0.5145   Best_Val_AUC=0.5330\n",
            "Epoch : 194\n",
            "Iteration started\n",
            "Epoch : 195  Train Loss : -0.14446 Val Loss : 3.10056   BatchID= 0   Val_AUC=0.5110   Best_Val_AUC=0.5330\n",
            "Epoch : 195\n",
            "Iteration started\n",
            "Epoch : 196  Train Loss : 0.12174 Val Loss : 3.04068   BatchID= 0   Val_AUC=0.5060   Best_Val_AUC=0.5330\n",
            "Epoch : 196\n",
            "Iteration started\n",
            "Epoch : 197  Train Loss : -0.49120 Val Loss : 3.09963   BatchID= 0   Val_AUC=0.5022   Best_Val_AUC=0.5330\n",
            "Epoch : 197\n",
            "Iteration started\n",
            "Epoch : 198  Train Loss : 0.10033 Val Loss : 3.13197   BatchID= 0   Val_AUC=0.5051   Best_Val_AUC=0.5330\n",
            "Epoch : 198\n",
            "Iteration started\n",
            "Epoch : 199  Train Loss : 0.12098 Val Loss : 3.10719   BatchID= 0   Val_AUC=0.5034   Best_Val_AUC=0.5330\n",
            "Epoch : 199\n"
          ]
        }
      ],
      "source": [
        "lr = 0.1 # using smaller learning rate is better\n",
        "epoch_decay = 0.03\n",
        "weight_decay = 1e-5\n",
        "margin = 1.0\n",
        "\n",
        "model = resnet18(num_classes=14)\n",
        "model = model.cuda()\n",
        "criterion = AUCMLoss()\n",
        "optimizer = PESG(model, \n",
        "                 loss_fn=criterion, \n",
        "                 lr=lr, \n",
        "                 margin=margin, \n",
        "                 epoch_decay=epoch_decay, \n",
        "                 weight_decay=weight_decay)\n",
        "\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(200):\n",
        "    train_losses = []\n",
        "    for idx, data in enumerate(train_loader):\n",
        "      print(\"Iteration started\")\n",
        "      train_data, train_labels = data\n",
        "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
        "      y_pred = model(train_data)\n",
        "      y_pred = torch.sigmoid(y_pred)\n",
        "      loss = criterion(y_pred, train_labels.type(torch.LongTensor).cuda())\n",
        "      train_losses.append(loss.item()/len(data))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      break\n",
        "\n",
        "    print(\"Epoch : {:03d}  Train Loss : {:.5f} \".format(epoch, np.mean(train_losses)), end='')\n",
        "    model.eval()\n",
        "    with torch.no_grad():    \n",
        "        test_pred = []\n",
        "        test_true = [] \n",
        "        test_losses = []\n",
        "        test_CE_losses = []\n",
        "        for jdx, data in enumerate(test_loader):\n",
        "            test_data, test_labels = data\n",
        "            test_data = test_data.cuda()\n",
        "            y_pred = model(test_data)\n",
        "            test_pred.append(y_pred.cpu().detach().numpy())\n",
        "            test_true.append(test_labels.numpy())\n",
        "            test_losses.append(criterion(y_pred, test_labels.squeeze().type(torch.LongTensor).cuda()).item() / len(data))\n",
        "\n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        val_auc_mean = 0\n",
        "        for i in range(14):\n",
        "            val_auc_mean +=  roc_auc_score(test_true[:,i], test_pred[:,i]) \n",
        "        val_auc_mean/=14\n",
        "        print(\"Val Loss : {:.5f}   \".format(np.mean(test_losses)), end = '')\n",
        "        model.train()\n",
        "\n",
        "        if best_val_auc < val_auc_mean:\n",
        "            best_val_auc = val_auc_mean\n",
        "            torch.save(model.state_dict(), 'pretrained_model.pth')\n",
        "\n",
        "        print ('BatchID= {}   Val_AUC={:.4f}   Best_Val_AUC={:.4f}'.format(\n",
        "            idx, val_auc_mean, best_val_auc ))\n",
        "          \n",
        "    print(\"Epoch : {}\".format(epoch))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "isr_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}